{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b8b21d",
   "metadata": {},
   "source": [
    "### Imports e Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5254cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a9ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/17 14:15:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando a sessão do Spark\n",
    "spark  = SparkSession.builder \\\n",
    "    .appName(\"Data Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\")\\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .config(\"spark.executor.cores\", \"4\")\\\n",
    "    .config(\"spark.executor.instances\",\"8\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\",\"96\")\\\n",
    "    .config(\"spark.default.parallelism\",\"96\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787acd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumRows\", 300)\n",
    "\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 100)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None) \n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bdd252",
   "metadata": {},
   "source": [
    "### Lendo dados enriquecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64224f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_input = (spark\n",
    "            .read\n",
    "            .parquet('/home/ricardo.neto/Documents/banco_original_enriched'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6e5cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24696018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee8ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_cidacs_sinasc_v4',\n",
       " 'id_cidacs_mae_sinasc',\n",
       " 'apgar1_sinasc',\n",
       " 'apgar5_sinasc',\n",
       " 'cod_raca_cor_pessoa_eq',\n",
       " 'codanomal_sinasc',\n",
       " 'codmunres_sinasc',\n",
       " 'codocupmae_sinasc',\n",
       " 'consprenat_sinasc',\n",
       " 'consultas_sinasc',\n",
       " 'dt_notific_mae',\n",
       " 'dtnasc_sinasc',\n",
       " 'dtnascmae_sinasc',\n",
       " 'dtobito_sim.y',\n",
       " 'escmae_sinasc',\n",
       " 'estcivmae_sinasc',\n",
       " 'gravidez_sinasc',\n",
       " 'id_agravo_mae',\n",
       " 'idademae_sinasc',\n",
       " 'idanomal_sinasc',\n",
       " 'mesprenat_sinasc',\n",
       " 'obitograv_sim.y',\n",
       " 'obitopuerp_sim.y',\n",
       " 'parto_sinasc',\n",
       " 'peso_sinasc',\n",
       " 'qtdfilmort_sinasc',\n",
       " 'qtdfilvivo_sinasc',\n",
       " 'semagestac_sinasc',\n",
       " 'sexo_sinasc',\n",
       " 'tipobito_sim.y',\n",
       " 'tpapresent_sinasc',\n",
       " 'tpconfirma_mae',\n",
       " 'tpesquema_mae',\n",
       " 'tpevidenci_mae',\n",
       " 'tpteste1_mae',\n",
       " 'tra_dt_sc',\n",
       " 'person_id',\n",
       " 'person_id_infant',\n",
       " 'location_id',\n",
       " 'dt_nascimento_calc_mae']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21352a3",
   "metadata": {},
   "source": [
    "### Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b364336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mãe que morreram durante o parto?\n",
    "df_death = (df_input\n",
    "            .withColumn('death_date', F.to_date(F.col('`dtobito_sim.y`'), 'yyyy-MM-dd')) # Essa é a data de óbito da mãe ou da criança?\n",
    "            .withColumn('death_datetime', F.lit(None).cast('timestamp'))\n",
    "            .withColumn('death_type_concept_id', F.lit(32849))\n",
    "            .withColumn('cause_concept_id', F.lit(None).cast('int'))\n",
    "            .withColumn('cause_source_value', F.lit(None).cast('string'))\n",
    "            .withColumn('cause_source_concept_id', F.lit(None).cast('int'))\n",
    "            .filter(F.col('death_date').isNotNull())\n",
    "           ).select('person_id', 'death_date', 'death_datetime',\n",
    "                    'death_type_concept_id', 'cause_concept_id', 'cause_source_value',\n",
    "                    'cause_source_concept_id') \n",
    "\n",
    "df_death.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8976f",
   "metadata": {},
   "source": [
    "### Salvando CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77898bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_death.repartition(1).write.option(\"quoteAll\",True).csv('/home/ricardo.neto/Documents/df_death', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beea3f6",
   "metadata": {},
   "source": [
    "## SQL de insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- CREATE TABLE public.death (\n",
    "-- \t\t\tperson_id integer NOT NULL,\n",
    "-- \t\t\tdeath_date date NOT NULL,\n",
    "-- \t\t\tdeath_datetime TIMESTAMP NULL,\n",
    "-- \t\t\tdeath_type_concept_id integer NULL,\n",
    "-- \t\t\tcause_concept_id integer NULL,\n",
    "-- \t\t\tcause_source_value varchar(50) NULL,\n",
    "-- \t\t\tcause_source_concept_id integer NULL );\n",
    "\n",
    "\n",
    "\n",
    "-- CREATE TABLE public.death_pyspark (\n",
    "-- \t\t\tperson_id varchar,\n",
    "-- \t\t\tdeath_date varchar,\n",
    "-- \t\t\tdeath_datetime varchar,\n",
    "-- \t\t\tdeath_type_concept_id varchar,\n",
    "-- \t\t\tcause_concept_id varchar,\n",
    "-- \t\t\tcause_source_value varchar,\n",
    "-- \t\t\tcause_source_concept_id varchar);\n",
    "\n",
    "\n",
    "insert into public.death (\n",
    "\tperson_id ,\n",
    "\tdeath_date ,\n",
    "\tdeath_datetime ,\n",
    "\tdeath_type_concept_id ,\n",
    "\tcause_concept_id ,\n",
    "\tcause_source_value ,\n",
    "\tcause_source_concept_id \n",
    ")\n",
    "SELECT \n",
    "\tcast(person_id as integer),\n",
    "\tcast(death_date as date),\n",
    "\tcast(case when death_datetime='' then null else death_datetime end as timestamp),\n",
    "\tcast(case when death_type_concept_id='' then null else death_type_concept_id end as integer),\n",
    "\tcast(case when cause_concept_id='' then null else cause_concept_id end as integer),\n",
    "\tcause_source_value,\n",
    "\tcast(case when cause_source_concept_id='' then null else cause_source_concept_id end as integer) \n",
    "\tFROM public.death_pyspark;\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9841ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b54340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfd901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/IDAF/PROJETOS/PARCERIA_CIDACS_PHDC/omop_scripts_base_16mi_karine/csv/observation_batch'\n",
    "\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3ec7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_temporary']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced2f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
