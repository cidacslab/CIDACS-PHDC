{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab38fe7b-cf6f-41dc-b3bc-bb991f08c261",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c543bc-e3b0-4393-8689-24fbf7269f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/17 13:47:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/17 13:47:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark  = SparkSession.builder \\\n",
    "    .appName(\"Data Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\")\\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .config(\"spark.executor.cores\", \"4\")\\\n",
    "    .config(\"spark.executor.instances\",\"8\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\",\"96\")\\\n",
    "    .config(\"spark.default.parallelism\",\"96\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2423060-1907-4415-839d-99b17919cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e0fc02-82f9-4d81-84ed-44192a2cae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumRows\", 300)\n",
    "\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 100)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None) \n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1ef39ea8-286e-4adc-a625-8be3c2bd288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar estes arquivos em parquet\n",
    "\n",
    "\n",
    "# db_original_paths\n",
    "path_one = '/data/IDAF/DB_ORIGINAL/ch-9422/saida_curadoria_17032025/' \n",
    "path_two = '/data/IDAF/DB_ORIGINAL/ch-9440/saida_curadoria_19032025/'\n",
    "path_three = '/data/IDAF/DB_ORIGINAL/ch-9496/saida_curadoria_29032025/'  \n",
    "# karine_path \n",
    "path_karine = '/data/IDAF/PROJETOS/PARCERIA_CIDACS_PHDC/Karine/Banco/' \n",
    "\n",
    "\n",
    "# path_salvamento \n",
    "\n",
    "path_salvamento = '/data/IDAF/PROJETOS/PARCERIA_CIDACS_PHDC/parquet_transformation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b86e6fd0-8b89-486e-85d2-3c35a4224d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_files(reading_path, saving_path): \n",
    "    files = os.listdir(reading_path)\n",
    "    for file in files: \n",
    "        if not str(file).endswith('.csv'):\n",
    "            files.remove(file)\n",
    "        \n",
    "        df = spark.read.csv(reading_path+file, header=True)\n",
    "        df.write.parquet(path_salvamento + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "193a0d6e-f97b-4f27-8107-6e3a96da3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/17 16:51:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , apgar1_sinasc, apgar5_sinasc, cod_raca_cor_pessoa_eq, codanomal_sinasc, codmunres_sinasc, codocupmae_sinasc, consprenat_sinasc, consultas_sinasc, dt_notific_mae, dtnasc_sinasc, dtnascmae_sinasc, dtobito_sim.y, escmae_sinasc, estcivmae_sinasc, gravidez_sinasc, id_agravo_mae, id_cidacs_mae_sinasc, id_cidacs_sinasc_v4, idademae_sinasc, idanomal_sinasc, mesprenat_sinasc, obitograv_sim.y, obitopuerp_sim.y, parto_sinasc, peso_sinasc, qtdfilmort_sinasc, qtdfilvivo_sinasc, semagestac_sinasc, sexo_sinasc, tipobito_sim.y, tpapresent_sinasc, tpconfirma_mae, tpesquema_mae, tpevidenci_mae, tpteste1_mae, tra_dt_sc\n",
      " Schema: _c0, apgar1_sinasc, apgar5_sinasc, cod_raca_cor_pessoa_eq, codanomal_sinasc, codmunres_sinasc, codocupmae_sinasc, consprenat_sinasc, consultas_sinasc, dt_notific_mae, dtnasc_sinasc, dtnascmae_sinasc, dtobito_sim.y, escmae_sinasc, estcivmae_sinasc, gravidez_sinasc, id_agravo_mae, id_cidacs_mae_sinasc, id_cidacs_sinasc_v4, idademae_sinasc, idanomal_sinasc, mesprenat_sinasc, obitograv_sim.y, obitopuerp_sim.y, parto_sinasc, peso_sinasc, qtdfilmort_sinasc, qtdfilvivo_sinasc, semagestac_sinasc, sexo_sinasc, tipobito_sim.y, tpapresent_sinasc, tpconfirma_mae, tpesquema_mae, tpevidenci_mae, tpteste1_mae, tra_dt_sc\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///data/IDAF/PROJETOS/PARCERIA_CIDACS_PHDC/Karine/Banco/bancofinal.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transforming_files(path_karine, path_salvamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a73a059-b870-4ede-93b2-0e45828a7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/data/IDAF/DB_ORIGINAL/ch-9440/saida_curadoria_19032025/02_pcwc_20250317_base_sinasc_v5_2011_2020_base_sim_v4_2011_2020.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9c8b1ca-2a78-4056-8133-872e86563db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(regiao_sinasc='5', racacormae_sinasc='4', apgar1_sinasc='1', codanomal_sinasc=None, idanomal_sinasc='2', dtnascmae_sinasc='1989-03-12', dtultmenst_sinasc='2011-07-06', escmae_sinasc='4', peso_sinasc='616', idademae_sinasc='22', codmunres_sinasc='510730', dtnasc_sinasc='2012-01-06', parto_sinasc='1', qtdfilmort_sinasc='0', sexo_sinasc='1', consultas_sinasc='3', qtdfilvivo_sinasc='0', locnasc_sinasc='1', qtdgestant_sinasc='0', consprenat_sinasc='5', id_cidacs_sinasc_v5='375204091', tpapresent_sinasc='2', mesprenat_sinasc='2', semagestac_sinasc='26', gravidez_sinasc='1', apgar5_sinasc='1', gestacao_sinasc='2', estcivmae_sinasc='5', tpmorteoco_sim='0', ano_base_sim='2012', id_cidacs_sim_v4='151238998', tpobitocor_sim=None, obitoparto_sim='3', morteparto_sim=None, semagestac_sim='26', lococor_sim='1', dtobito_sim='2012-01-24', tipobito_sim='2')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d37e68-30fd-47df-b48c-59676d037bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
